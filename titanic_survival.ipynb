{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# python staples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "# scikitlearn\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "# seaborn plotting\n",
    "import seaborn as sns\n",
    "# use matplot |in jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def confusion_summary_binary(y_actual, y_pred, verbose):\n",
    "    # get success and failur\n",
    "    tot_tested = len(y_actual)\n",
    "    tot_success = sum( y_actual )\n",
    "    tot_fail = tot_tested - tot_success\n",
    "    pred_success = sum( y_pred )\n",
    "    pred_fail = tot_tested - pred_success\n",
    "    # see how you did\n",
    "    confusion_mat = confusion_matrix(y_actual, y_pred)\n",
    "    confusion_mat_norm = confusion_mat / tot_tested\n",
    "    accuracy = confusion_mat_norm[0,0] + confusion_mat_norm[1,1]\n",
    "    recall = confusion_mat[0,0] / tot_success\n",
    "    precision = confusion_mat[0,1] / pred_success\n",
    "    f1 = 2 / ( 1/recall + 1/precision)\n",
    "    summary = {\"confusion\": confusion_mat, \"confusion_norm\": confusion_mat_norm,\n",
    "               \"recall\": recall, \"precision\": precision, \"f1\": f1,\n",
    "               \"accuracy\": accuracy}\n",
    "    if verbose == 1:\n",
    "        print('accuracy = ', accuracy )\n",
    "        print('recall = ', recall )\n",
    "        print('precision = ', precision )\n",
    "        print('f1 =', f1  )\n",
    "    return summary\n",
    "\n",
    "def clean_data( mydata, drop_list, verbose ):\n",
    "    # some data is pointless, get rid of id\n",
    "    mydata = mydata.drop( drop_list, axis=1 )\n",
    "    # clean it\n",
    "    # find isnan value\n",
    "    if verbose == 1:\n",
    "        print( 'before clean isnan check:\\n', mydata.isna().any() )\n",
    "    # turn male/female, embarked to a number\n",
    "    mydata.loc[mydata.Sex == 'female','Sex' ] = 0\n",
    "    mydata.loc[mydata.Sex == 'male','Sex' ] = 1\n",
    "    mydata.loc[mydata.Embarked == 'S','Embarked' ] = 0\n",
    "    mydata.loc[mydata.Embarked == 'C','Embarked' ] = 1\n",
    "    mydata.loc[mydata.Embarked == 'Q','Embarked' ] = 2\n",
    "    # replace nan with average\n",
    "    mydata.loc[mydata.Age.isnull(),'Age']  = np.mean( mydata.Age[~mydata.Age.isna()] )\n",
    "    mydata.loc[mydata.Fare.isnull(),'Fare']  = np.mean( mydata.Fare[~mydata.Fare.isna()] )\n",
    "    mydata.loc[mydata.Embarked.isna(),'Embarked'] = mydata.mode().Embarked[0]\n",
    "    #normalize\n",
    "    mydata = ( mydata - mydata.mean() ) / mydata.std()\n",
    "    if verbose:\n",
    "        print('after clean isnan check:\\n', mydata.isna().any() )\n",
    "        print( 'Cleaned data:', mydata.iloc[0] )\n",
    "    return mydata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data set:\n",
      "\n",
      " PassengerId                          1\n",
      "Survived                             0\n",
      "Pclass                               3\n",
      "Name           Braund, Mr. Owen Harris\n",
      "Sex                               male\n",
      "Age                                 22\n",
      "SibSp                                1\n",
      "Parch                                0\n",
      "Ticket                       A/5 21171\n",
      "Fare                              7.25\n",
      "Cabin                              NaN\n",
      "Embarked                             S\n",
      "Name: 0, dtype: object\n",
      "Original test data set:\n",
      "\n",
      " PassengerId                 892\n",
      "Pclass                        3\n",
      "Name           Kelly, Mr. James\n",
      "Sex                        male\n",
      "Age                        34.5\n",
      "SibSp                         0\n",
      "Parch                         0\n",
      "Ticket                   330911\n",
      "Fare                     7.8292\n",
      "Cabin                       NaN\n",
      "Embarked                      Q\n",
      "Name: 0, dtype: object\n",
      "\n",
      " features: 11\n"
     ]
    }
   ],
   "source": [
    "# grab the data and put it in a pandas dataframe\n",
    "df_train_all = pd.read_csv('train.csv')\n",
    "df_test_all = pd.read_csv('test.csv')\n",
    "# print some info\n",
    "print('Original train data set:\\n\\n', df_train_all.iloc[0])\n",
    "print('Original test data set:\\n\\n', df_test_all.iloc[0])\n",
    "num_features = len( df_train_all.columns ) - 1\n",
    "print('\\n features:', num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set:\n",
      " Pclass      0.843218\n",
      "Sex         0.720067\n",
      "Age        -0.867380\n",
      "SibSp      -0.493610\n",
      "Fare       -0.654592\n",
      "Embarked   -0.562464\n",
      "Name: 302, dtype: float64\n",
      "Data set:\n",
      " Pclass      0.872436\n",
      "Sex         0.755024\n",
      "Age         0.334592\n",
      "SibSp      -0.498872\n",
      "Fare       -0.497811\n",
      "Embarked    2.240480\n",
      "Name: 0, dtype: float64\n",
      "\n",
      " test samples: 418\n",
      "\n",
      " train samples: 588\n",
      "\n",
      " cv samples: 303\n",
      "\n",
      " features: 6 6\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "drop_list = ['Parch','PassengerId','Name','Ticket', 'Cabin']\n",
    "# break the y data to train, validation set\n",
    "train_frac = 0.66;\n",
    "num_tot = len( df_train_all.index)\n",
    "num_train = np.round( num_tot * train_frac )\n",
    "num_validation = num_tot - num_train;\n",
    "ind_train = np.random.choice(int(num_tot), int(num_train), replace=False)\n",
    "ind_all = np.arange(num_tot)\n",
    "ind_cv = np.delete( ind_all, ind_train )\n",
    "y_train = df_train_all.Survived.iloc[ind_train]\n",
    "y_cv = df_train_all.Survived.iloc[ind_cv]\n",
    "# clean it\n",
    "df_train = clean_data( df_train_all.iloc[ind_train], drop_list, 0)\n",
    "df_cv = clean_data( df_train_all.iloc[ind_cv], drop_list, 0)\n",
    "df_test = clean_data( df_test_all, drop_list, 0)\n",
    "df_train.Survived = y_train\n",
    "x_train = df_train.drop('Survived', axis=1)\n",
    "x_cv = df_cv.drop('Survived', axis=1)\n",
    "x_test = df_test\n",
    "# print some info\n",
    "num_features_test = len( x_test.columns )\n",
    "num_features_train = len( x_train.columns )\n",
    "print( 'Data set:\\n', x_train.iloc[0])\n",
    "print( 'Data set:\\n', x_test.iloc[0])\n",
    "print('\\n test samples:', len( df_test.index) )\n",
    "print('\\n train samples:', len( df_train.index) )\n",
    "print('\\n cv samples:', len( df_cv.index) )\n",
    "print('\\n features:', num_features_test, num_features_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(df_train, hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "# 2d\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(x_train)\n",
    "x_transform2 = pca2.transform(x_train)\n",
    "plt.scatter( x_transform2[:,0], x_transform2[:,1], c = y_train )\n",
    "plt.title('PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.7788778877887789\n",
      "recall =  1.3909090909090909\n",
      "precision =  0.3252032520325203\n",
      "f1 = 0.5271544855506266\n"
     ]
    }
   ],
   "source": [
    "# sci-kit learn logistic regression\n",
    "logistic = linear_model.LogisticRegression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(x_train, y_train)\n",
    "#print(x_test.isna().any())\n",
    "log_pred = logistic.predict(x_cv)\n",
    "#log_correct = np.sum(log_pred == y_test) / np.size( y_test )\n",
    "# f1, recall, precision test\n",
    "log_sum = confusion_summary_binary( y_cv, log_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.467547\n",
      "         Iterations 7\n",
      "                        Results: Logit\n",
      "===============================================================\n",
      "Model:              Logit            No. Iterations:   7.0000  \n",
      "Dependent Variable: Survived         Pseudo R-squared: 0.303   \n",
      "Date:               2018-02-18 17:45 AIC:              561.8349\n",
      "No. Observations:   588              BIC:              588.0953\n",
      "Df Model:           5                Log-Likelihood:   -274.92 \n",
      "Df Residuals:       582              LL-Null:          -394.40 \n",
      "Converged:          1.0000           Scale:            1.0000  \n",
      "----------------------------------------------------------------\n",
      "            Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "----------------------------------------------------------------\n",
      "Pclass     -0.8714    0.1496   -5.8243  0.0000  -1.1646  -0.5781\n",
      "Sex        -1.2610    0.1171  -10.7730  0.0000  -1.4905  -1.0316\n",
      "Age        -0.4858    0.1220   -3.9837  0.0001  -0.7249  -0.2468\n",
      "SibSp      -0.3241    0.1261   -2.5712  0.0101  -0.5712  -0.0770\n",
      "Fare        0.2339    0.1928    1.2129  0.2252  -0.1440   0.6118\n",
      "Embarked    0.1193    0.1079    1.1059  0.2688  -0.0921   0.3307\n",
      "===============================================================\n",
      "\n",
      "accuracy =  0.7722772277227723\n",
      "recall =  1.309090909090909\n",
      "precision =  0.35251798561151076\n",
      "f1 = 0.5554593403133118\n"
     ]
    }
   ],
   "source": [
    "# Logistical fit using sm.Logit\n",
    "logistic2 = sm.Logit(y_train, x_train)\n",
    "# fit the model\n",
    "result = logistic2.fit()\n",
    "print( result.summary2() )\n",
    "#print(result.params)\n",
    "log2_pred = result.predict(x_cv)\n",
    "# this regression return sigmoid hypothesis. Round it\n",
    "log2_pred = np.int8( np.round(log_pred2) )\n",
    "log2_sum = confusion_summary_binary( y_cv, log2_pred,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.7986798679867987\n",
      "recall =  1.490909090909091\n",
      "precision =  0.27102803738317754\n",
      "f1 = 0.45867489632558583\n"
     ]
    }
   ],
   "source": [
    "# linear discriminant analysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_pred = lda.predict(x_cv)\n",
    "# f1, recall, precision test\n",
    "lda_sum = confusion_summary_binary( y_cv, lda_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.7854785478547855\n",
      "recall =  1.5\n",
      "precision =  0.27722772277227725\n",
      "f1 = 0.467966573816156\n"
     ]
    }
   ],
   "source": [
    "# SVM: linear kernal\n",
    "linear_svc = SVC(kernel='linear')\n",
    "linear_svc.fit(x_train, y_train)\n",
    "linear_svc_pred = linear_svc.predict(x_cv)\n",
    "linear_svc_sum = confusion_summary_binary( y_cv, linear_svc_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8184818481848185\n",
      "recall =  1.6181818181818182\n",
      "precision =  0.17647058823529413\n",
      "f1 = 0.3182359952324196\n"
     ]
    }
   ],
   "source": [
    "# SVM: gaussian kernal\n",
    "gaussian_svc = SVC(kernel='rbf')\n",
    "gaussian_svc.fit(x_train, y_train)\n",
    "gaussian_svc_pred = gaussian_svc.predict(x_cv)\n",
    "gaussian_svc_sum = confusion_summary_binary( y_cv, gaussian_svc_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8250825082508251\n",
      "recall =  1.4201680672268908\n",
      "precision =  0.15625\n",
      "f1 = 0.28152590371480923\n"
     ]
    }
   ],
   "source": [
    "# knn \n",
    "n_neighbors = 12\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_cv)\n",
    "knn_sum = confusion_summary_binary( y_cv, knn_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.7590759075907592\n",
      "recall =  1.3361344537815125\n",
      "precision =  0.2604166666666667\n",
      "f1 = 0.43587916004166893\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "randfor = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "randfor.fit(x_train, y_train)\n",
    "randfor_pred = randfor.predict(x_cv)\n",
    "randfor_sum = confusion_summary_binary( y_cv, randfor_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "log        0.778878\n",
      "log2       0.772277\n",
      "lda        0.798680\n",
      "lin_svm    0.785479\n",
      "gauss_svm  0.818482\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "model_pred_df = pd.DataFrame( {'Truth': y_cv.values, 'logreg sklearn': log_pred, \n",
    "                          'logreg logit': log_pred2, 'lda': lda_pred, \n",
    "                            'lin svm': linear_svc_pred, 'gaussian svm': gaussian_svc_pred} )\n",
    "model_sum_df = pd.DataFrame([ log_sum['accuracy'], \n",
    "                             log2_sum['accuracy'], lda_sum['accuracy'], \n",
    "                             linear_svc_sum['accuracy'], \n",
    "                            gaussian_svc_sum['accuracy'] ], \n",
    "                            index = ['log','log2','lda','lin_svm','gauss_svm'])\n",
    "print( model_sum_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_sum_df = pd.DataFrame([ log_sum['accuracy'], \n",
    "                             log2_sum['accuracy'], lda_sum['accuracy'], \n",
    "                             linear_svc_sum['accuracy'], \n",
    "                            gaussian_svc_sum['accuracy'] ], \n",
    "                            index = ['log','log2','lda','lin_svm','gauss_svm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf2.predict( x_cv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
